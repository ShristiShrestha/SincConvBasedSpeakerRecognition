<!DOCTYPE html>
<html theme="light" style="overflow-y: auto;"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><meta charset="UTF-8">
<script>
  // Avoid arrow function syntax to stay ES5 compatible for the sake of googlebot.
  window.addEventListener('message', function(message)  {
    if (message.source != window.parent) {
      return;
    }
    if (message.data.sandboxed_iframe_evaluation) {
      // Message is available in scope so evaluated script can get params from
      // it.
      window.currentMessage = message;
      eval.call(null, message.data.sandboxed_iframe_evaluation);
      delete window.currentMessage;
    }
  });
</script>
<meta http-equiv="origin-trial" content="AjwRCfXAVG3Lei9P2OFIPHGMwOjtj2fK2n2G+8oQMOuHnA5vw5vkPH3VLbkpwopHXVpAYQUs+owTgqDi9F3rCwsAAABxeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXVzZXJjb250ZW50LmNvbTo0NDMiLCJmZWF0dXJlIjoiV2ViQ29tcG9uZW50c1YwIiwiZXhwaXJ5IjoxNTY2MjM2MjAwLCJpc1N1YmRvbWFpbiI6dHJ1ZX0="><style>html{--paper-blue-200:#90caf9;--paper-blue-400:#42a5f5;--paper-blue-500:#2196f3;--paper-blue-700:#1976d2;--paper-blue-900:#0d47a1;--paper-blue-a100:#82b1ff;--paper-blue-a200:#448aff;--paper-blue-a400:#2979ff;--paper-blue-a700:#2962ff;--paper-orange-50:#fff3e0;--paper-orange-100:#ffe0b2;--paper-orange-200:#ffcc80;--paper-orange-300:#ffb74d;--paper-orange-400:#ffa726;--paper-orange-500:#ff9800;--paper-orange-700:#f57c00;--paper-grey-50:#fafafa;--paper-grey-100:#f5f5f5;--paper-grey-200:#eeeeee;--paper-grey-300:#e0e0e0;--paper-grey-400:#bdbdbd;--paper-grey-500:#9e9e9e;--paper-grey-600:#757575;--paper-grey-700:#616161;--paper-grey-800:#424242;--paper-grey-900:#212121;--paper-red-100:#ffcdd2;--paper-red-a700:#d50000;--paper-green-a700:#00c853;--paper-white:#ffffff;--google-blue-500:#4285f4;--box-shadow-elevation-2dp:0 2px 2px 0 rgba(0,0,0,0.14),0 1px 5px 0 rgba(0,0,0,0.12),0 3px 1px -2px rgba(0,0,0,0.2);--box-shadow-elevation-3dp:0 3px 4px 0 rgba(0,0,0,0.14),0 1px 8px 0 rgba(0,0,0,0.12),0 3px 3px -2px rgba(0,0,0,0.4);--paper-font-subhead-font-size:16px;--paper-font-subhead-font-weight:400;--paper-font-subhead-line-height:24px;--paper-font-body1-font-weight:400;--paper-font-body1-line-height:20px}html{overflow-y:hidden}body{background:var(--colab-primary-surface-color);color:var(--colab-primary-text-color);font-family:var(--colab-chrome-font-family);font-size:14px;line-height:1.24;font-weight:400;padding:7px 0 10px 5px;margin:0}h1,h2,h3,h4,h5,h6{color:var(--colab-primary-text-color);font-family:var(--colab-chrome-font-family);font-weight:700;margin-bottom:4px}p,ul{margin-bottom:6px;margin-top:6px}pre{margin-bottom:0px;margin-top:0px}a{color:var(--colab-anchor-color)}div.stream,div.pyout,div.output_text,div.output_text pre{display:inline}table.dataframe{border-collapse:collapse;border-spacing:0;border:none;table-layout:fixed}table.dataframe thead{border-bottom:1px solid var(--colab-border-color);font-family:var(--colab-code-font-family);text-align:right}table.dataframe tr,table.dataframe th,table.dataframe td{border:none;padding:0.5em;white-space:normal}table.dataframe th{font-weight:bold}table.dataframe th.col_heading{text-align:right}table.dataframe tbody tr:nth-child(odd){background:var(--colab-secondary-surface-color)}table.dataframe tbody tr:hover,table.dataframe tbody tr:nth-child(odd):hover{background-color:var(--colab-highlighted-surface-color)}table.dataframe td{text-align:right}table.dataTable input.text_filter{width:95%}table.dataTable th{text-align:left}.output_image>img{vertical-align:bottom}.ansibold{font-weight:bold}.ansiblack{color:black}.ansired{color:darkred}.ansigreen{color:darkgreen}.ansiyellow{color:brown}.ansiblue{color:darkblue}.ansipurple{color:darkviolet}.ansicyan{color:steelblue}.ansigray{color:gray}.ansibgblack{background-color:black}.ansibgred{background-color:red}.ansibggreen{background-color:green}.ansibgyellow{background-color:yellow}.ansibgblue{background-color:blue}.ansibgpurple{background-color:magenta}.ansibgcyan{background-color:cyan}.ansibggray{background-color:gray}.output-error span{font-weight:normal!important}input.raw_input{font-family:var(--colab-code-font-family);width:90%}input{background:var(--colab-primary-surface-color);border:1px solid var(--colab-bold-border-color);color:var(--colab-primary-text-color)}#output-area{display:flow-root}#output-area button.colab{background-color:var(--colab-secondary-surface-color);border:0;box-shadow:var(--box-shadow-elevation-3dp);color:var(--colab-primary-text-color);font-family:var(--colab-chrome-font-family);font-size:11px;margin:0px 4px;padding:6px;text-transform:uppercase;user-select:none}#output-area button.colab:hover{background-color:var(--colab-highlighted-surface-color);cursor:pointer}#output-area .output-error button.error-details{background-color:#42a5f5;color:white}#output-area .output-error button.error-details:hover{background-color:#2196f3}#output-area .stdin-widget{align-items:center;display:inline;font-family:var(--colab-code-font-family);margin-right:10px;margin-top:10px;min-width:250px;padding:1px}#output-area .stdin-widget-hidden{visibility:hidden}.pyerr .collapsed .extraneous{display:none}.pyerr .error-expander{align-items:center;cursor:pointer;display:flex}.pyerr .error-expander hr{border:0;border-top:1px solid var(--colab-bold-border-color);flex-grow:1;height:1px;margin:0 10px;padding:0}.pyerr .error-expander hr:first-child{max-width:240px}.pyerr .error-expander svg{fill:var(--colab-icon-color);height:24px;stroke:var(--colab-icon-color);width:24px}html{--colab-anchor-color:#0000ee;--colab-primary-text-color:var(--paper-grey-900);--colab-primary-surface-color:var(--paper-white);--colab-secondary-surface-color:#f7f7f7;--colab-highlighted-surface-color:var(--paper-grey-300);--colab-border-color:#dadada;--colab-bold-border-color:#111;--colab-icon-color:#616161;--ansi-black:rgb(0,0,0);--ansi-red:rgb(139,0,0);--ansi-green:rgb(0,100,0);--ansi-yellow:rgb(205,205,0);--ansi-blue:rgb(0,0,238);--ansi-magenta:rgb(205,0,205);--ansi-cyan:rgb(70,130,180);--ansi-gray:rgb(229,229,229);--ansi-bright-black:rgb(127,127,127);--ansi-bright-red:rgb(255,0,0);--ansi-bright-green:rgb(0,255,0);--ansi-bright-yellow:rgb(255,255,0);--ansi-bright-blue:rgb(92,92,255);--ansi-bright-magenta:rgb(255,0,255);--ansi-bright-cyan:rgb(0,255,255);--ansi-bright-gray:rgb(255,255,255);--colab-code-font-family:monospace;--colab-chrome-font-family:'Roboto','Noto',sans-serif}html[theme=dark]{--colab-anchor-color:var(--paper-blue-400);--colab-primary-text-color:#d5d5d5;--colab-primary-surface-color:#383838;--colab-secondary-surface-color:#454545;--colab-highlighted-surface-color:#525252;--colab-border-color:var(--paper-grey-900);--colab-bold-border-color:#eee;--colab-icon-color:#f5f5f5;--ansi-black:rgb(127,127,127);--ansi-red:rgb(255,122,136);--ansi-green:rgb(87,187,138);--ansi-yellow:rgb(255,255,102);--ansi-blue:rgb(130,177,255);--ansi-magenta:rgb(205,0,205);--ansi-cyan:rgb(153,187,215);--ansi-gray:rgb(229,229,229)}
//@ sourceURL=https://colab.research.google.com/v2/external/outputframe.css?vrz=colab-20190801-085300-RC01_261161127</style><!-- base href="https://localhost:8080/" --></head><body><div id="output-area"><span id="output-header"> </span><div id="output-body"><div class="stream"><div class="output_subarea output_text"><pre>Using TensorFlow backend.
{'cfg': 'trial_2.cfg', 'tr_lst': 'trial_2/trial_2_train.scp', 'te_lst': 'trial_2/trial_2_test.scp', 'lab_dict': 'trial_2/trial_2_all_label.npy', 'data_folder': '""', 'output_folder': 'trial_2_output', 'pt_file': 'trial_2_output/weights-improvement-356-0.72.hdf5', 'lowest_id': '0', 'fs': '8000', 'cw_len': '375', 'cw_shift': '10', 'cnn_N_filt': '80,60,60', 'cnn_len_filt': '253,7,7', 'cnn_max_pool_len': '3,3,3', 'cnn_use_laynorm_inp': 'True', 'cnn_use_batchnorm_inp': 'False', 'cnn_use_laynorm': 'True,True,True', 'cnn_use_batchnorm': 'False,False,False', 'cnn_act': 'leaky_relu,leaky_relu,leaky_relu', 'cnn_drop': '0.0,0.0,0.0', 'fc_lay': '2048,2048,2048', 'fc_drop': '0.0,0.0,0.0', 'fc_use_laynorm_inp': 'True', 'fc_use_batchnorm_inp': 'False', 'fc_use_batchnorm': 'True,True,True', 'fc_use_laynorm': 'False,False,False', 'fc_act': 'leaky_relu,leaky_relu,leaky_relu', 'class_lay': '265', 'class_drop': '0.0', 'class_use_laynorm_inp': 'False', 'class_use_batchnorm_inp': 'False', 'class_use_batchnorm': 'False', 'class_use_laynorm': 'False', 'class_act': 'softmax', 'lr': '0.001', 'batch_size': '128', 'N_epochs': '400', 'N_batches': '200', 'N_eval_epoch': '5', 'seed': '1234'}
WARNING: Logging before flag parsing goes to stderr.
W0730 20:39:59.833604 139793529894784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

W0730 20:39:59.834041 139793529894784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

W0730 20:39:59.875267 139793529894784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

W0730 20:39:59.875564 139793529894784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0730 20:39:59.993149 139793529894784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

2019-07-30 20:40:00.028577: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz
2019-07-30 20:40:00.030278: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x280ea00 executing computations on platform Host. Devices:
2019-07-30 20:40:00.030315: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
2019-07-30 20:40:00.047701: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-30 20:40:00.187196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-30 20:40:00.187762: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7299500 executing computations on platform CUDA. Devices:
2019-07-30 20:40:00.187797: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-07-30 20:40:00.188629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-30 20:40:00.190741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
2019-07-30 20:40:00.193780: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-07-30 20:40:00.209919: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-07-30 20:40:00.255941: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-07-30 20:40:00.263793: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-07-30 20:40:00.286249: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-07-30 20:40:00.304510: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-07-30 20:40:00.363812: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-07-30 20:40:00.363989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-30 20:40:00.364423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-30 20:40:00.364763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-07-30 20:40:00.367065: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-07-30 20:40:00.369157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-30 20:40:00.369222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-07-30 20:40:00.369258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-07-30 20:40:00.371604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-30 20:40:00.372169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-30 20:40:00.372621: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2019-07-30 20:40:00.372676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -&gt; physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
W0730 20:40:02.042381 139793529894784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:2618: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0730 20:40:08.029366 139793529894784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0730 20:40:08.467855 139793529894784 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 3000, 1)           0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 3000, 1)           4         
_________________________________________________________________
sinc__conv__layer_1 (Sinc_Co (None, 2748, 80)          160       
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 916, 80)           0         
_________________________________________________________________
layer__normalization_1 (Laye (None, 916, 80)           160       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 916, 80)           0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 910, 60)           33660     
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 303, 60)           0         
_________________________________________________________________
layer__normalization_2 (Laye (None, 303, 60)           120       
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 303, 60)           0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 297, 60)           25260     
_________________________________________________________________
max_pooling1d_3 (MaxPooling1 (None, 99, 60)            0         
_________________________________________________________________
layer__normalization_3 (Laye (None, 99, 60)            120       
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 99, 60)            0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 93, 60)            25260     
_________________________________________________________________
max_pooling1d_4 (MaxPooling1 (None, 31, 60)            0         
_________________________________________________________________
layer__normalization_4 (Laye (None, 31, 60)            120       
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 31, 60)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1860)              0         
_________________________________________________________________
layer__normalization_5 (Laye (None, 1860)              3720      
_________________________________________________________________
dense_1 (Dense)              (None, 2048)              3811328   
_________________________________________________________________
batch_normalization_2 (Batch (None, 2048)              8192      
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 2048)              0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 2048)              0         
_________________________________________________________________
layer__normalization_6 (Laye (None, 2048)              4096      
_________________________________________________________________
dense_2 (Dense)              (None, 2048)              4196352   
_________________________________________________________________
batch_normalization_3 (Batch (None, 2048)              8192      
_________________________________________________________________
leaky_re_lu_6 (LeakyReLU)    (None, 2048)              0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 2048)              0         
_________________________________________________________________
layer__normalization_7 (Laye (None, 2048)              4096      
_________________________________________________________________
dense_3 (Dense)              (None, 2048)              4196352   
_________________________________________________________________
batch_normalization_4 (Batch (None, 2048)              8192      
_________________________________________________________________
leaky_re_lu_7 (LeakyReLU)    (None, 2048)              0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 2048)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 265)               542985    
=================================================================
Total params: 12,868,369
Trainable params: 12,856,079
Non-trainable params: 12,290
_________________________________________________________________
model summary:  None
W0730 20:40:08.836268 139793529894784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

W0730 20:40:13.373309 139793529894784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.&lt;locals&gt;.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0730 20:40:31.560864 139793529894784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

W0730 20:40:31.561218 139793529894784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

Epoch 357/400
2019-07-30 20:40:59.124995: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-07-30 20:40:59.938999: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
200/200 [==============================] - 185s 924ms/step - loss: 0.7376 - acc: 0.7971 - val_loss: 1.3229 - val_acc: 0.7188

Epoch 00357: saving model to trial_2_output/weights-improvement-357-0.72.hdf5
Epoch 358/400
200/200 [==============================] - 153s 766ms/step - loss: 0.6866 - acc: 0.8054 - val_loss: 1.0209 - val_acc: 0.7484

Epoch 00358: saving model to trial_2_output/weights-improvement-358-0.75.hdf5
Epoch 359/400
200/200 [==============================] - 162s 809ms/step - loss: 0.6720 - acc: 0.8123 - val_loss: 1.2628 - val_acc: 0.7109

Epoch 00359: saving model to trial_2_output/weights-improvement-359-0.71.hdf5
Epoch 360/400
200/200 [==============================] - 161s 805ms/step - loss: 0.6976 - acc: 0.8071 - val_loss: 0.9938 - val_acc: 0.7734

Epoch 00360: saving model to trial_2_output/weights-improvement-360-0.77.hdf5
Epoch 361/400
200/200 [==============================] - 156s 781ms/step - loss: 0.6862 - acc: 0.8075 - val_loss: 0.8574 - val_acc: 0.7750

Epoch 00361: saving model to trial_2_output/weights-improvement-361-0.78.hdf5
Epoch 362/400
200/200 [==============================] - 165s 824ms/step - loss: 0.6937 - acc: 0.8074 - val_loss: 1.0674 - val_acc: 0.7500

Epoch 00362: saving model to trial_2_output/weights-improvement-362-0.75.hdf5
Epoch 363/400
200/200 [==============================] - 163s 815ms/step - loss: 0.6968 - acc: 0.8052 - val_loss: 0.9199 - val_acc: 0.7703

Epoch 00363: saving model to trial_2_output/weights-improvement-363-0.77.hdf5
Epoch 364/400
200/200 [==============================] - 163s 814ms/step - loss: 0.6802 - acc: 0.8114 - val_loss: 1.1042 - val_acc: 0.7484

Epoch 00364: saving model to trial_2_output/weights-improvement-364-0.75.hdf5
Epoch 365/400
200/200 [==============================] - 162s 812ms/step - loss: 0.6827 - acc: 0.8097 - val_loss: 0.9717 - val_acc: 0.7859

Epoch 00365: saving model to trial_2_output/weights-improvement-365-0.79.hdf5
Epoch 366/400
200/200 [==============================] - 163s 813ms/step - loss: 0.6675 - acc: 0.8123 - val_loss: 1.0357 - val_acc: 0.7391

Epoch 00366: saving model to trial_2_output/weights-improvement-366-0.74.hdf5
Epoch 367/400
200/200 [==============================] - 159s 794ms/step - loss: 0.6875 - acc: 0.8080 - val_loss: 1.2166 - val_acc: 0.7141

Epoch 00367: saving model to trial_2_output/weights-improvement-367-0.71.hdf5
Epoch 368/400
200/200 [==============================] - 157s 786ms/step - loss: 0.6915 - acc: 0.8065 - val_loss: 1.0660 - val_acc: 0.7312

Epoch 00368: saving model to trial_2_output/weights-improvement-368-0.73.hdf5
Epoch 369/400
200/200 [==============================] - 156s 780ms/step - loss: 0.6877 - acc: 0.8109 - val_loss: 1.0148 - val_acc: 0.7609

Epoch 00369: saving model to trial_2_output/weights-improvement-369-0.76.hdf5
Epoch 370/400
200/200 [==============================] - 157s 785ms/step - loss: 0.6748 - acc: 0.8112 - val_loss: 0.9823 - val_acc: 0.7641

Epoch 00370: saving model to trial_2_output/weights-improvement-370-0.76.hdf5
Epoch 371/400
200/200 [==============================] - 153s 764ms/step - loss: 0.6942 - acc: 0.8082 - val_loss: 1.0973 - val_acc: 0.7562

Epoch 00371: saving model to trial_2_output/weights-improvement-371-0.76.hdf5
Epoch 372/400
200/200 [==============================] - 154s 769ms/step - loss: 0.6937 - acc: 0.8074 - val_loss: 1.0727 - val_acc: 0.7484

Epoch 00372: saving model to trial_2_output/weights-improvement-372-0.75.hdf5
Epoch 373/400
200/200 [==============================] - 160s 800ms/step - loss: 0.6625 - acc: 0.8130 - val_loss: 1.2696 - val_acc: 0.7281

Epoch 00373: saving model to trial_2_output/weights-improvement-373-0.73.hdf5
Epoch 374/400
200/200 [==============================] - 159s 794ms/step - loss: 0.6913 - acc: 0.8081 - val_loss: 1.2119 - val_acc: 0.7266

Epoch 00374: saving model to trial_2_output/weights-improvement-374-0.73.hdf5
Epoch 375/400
200/200 [==============================] - 158s 791ms/step - loss: 0.6857 - acc: 0.8085 - val_loss: 1.1316 - val_acc: 0.7531

Epoch 00375: saving model to trial_2_output/weights-improvement-375-0.75.hdf5
Epoch 376/400
200/200 [==============================] - 158s 789ms/step - loss: 0.6946 - acc: 0.8075 - val_loss: 1.1080 - val_acc: 0.7266

Epoch 00376: saving model to trial_2_output/weights-improvement-376-0.73.hdf5
Epoch 377/400
200/200 [==============================] - 155s 777ms/step - loss: 0.6989 - acc: 0.8076 - val_loss: 1.1948 - val_acc: 0.7375

Epoch 00377: saving model to trial_2_output/weights-improvement-377-0.74.hdf5
Epoch 378/400
200/200 [==============================] - 158s 788ms/step - loss: 0.6869 - acc: 0.8122 - val_loss: 1.3550 - val_acc: 0.6797

Epoch 00378: saving model to trial_2_output/weights-improvement-378-0.68.hdf5
Epoch 379/400
200/200 [==============================] - 155s 777ms/step - loss: 0.6600 - acc: 0.8157 - val_loss: 0.9418 - val_acc: 0.7625

Epoch 00379: saving model to trial_2_output/weights-improvement-379-0.76.hdf5
Epoch 380/400
200/200 [==============================] - 155s 776ms/step - loss: 0.6663 - acc: 0.8132 - val_loss: 1.1501 - val_acc: 0.7438

Epoch 00380: saving model to trial_2_output/weights-improvement-380-0.74.hdf5
Epoch 381/400
200/200 [==============================] - 155s 774ms/step - loss: 0.6648 - acc: 0.8132 - val_loss: 1.1392 - val_acc: 0.7250

Epoch 00381: saving model to trial_2_output/weights-improvement-381-0.72.hdf5
Epoch 382/400
200/200 [==============================] - 156s 778ms/step - loss: 0.6930 - acc: 0.8045 - val_loss: 1.0297 - val_acc: 0.7531

Epoch 00382: saving model to trial_2_output/weights-improvement-382-0.75.hdf5
Epoch 383/400
200/200 [==============================] - 156s 782ms/step - loss: 0.6636 - acc: 0.8161 - val_loss: 1.0027 - val_acc: 0.7578

Epoch 00383: saving model to trial_2_output/weights-improvement-383-0.76.hdf5
Epoch 384/400
200/200 [==============================] - 155s 775ms/step - loss: 0.6658 - acc: 0.8136 - val_loss: 1.0819 - val_acc: 0.7500

Epoch 00384: saving model to trial_2_output/weights-improvement-384-0.75.hdf5
Epoch 385/400
200/200 [==============================] - 154s 771ms/step - loss: 0.6776 - acc: 0.8108 - val_loss: 1.3494 - val_acc: 0.7047

Epoch 00385: saving model to trial_2_output/weights-improvement-385-0.70.hdf5
Epoch 386/400
200/200 [==============================] - 157s 783ms/step - loss: 0.6796 - acc: 0.8120 - val_loss: 1.1665 - val_acc: 0.7094

Epoch 00386: saving model to trial_2_output/weights-improvement-386-0.71.hdf5
Epoch 387/400
200/200 [==============================] - 159s 795ms/step - loss: 0.6621 - acc: 0.8123 - val_loss: 1.1550 - val_acc: 0.7250

Epoch 00387: saving model to trial_2_output/weights-improvement-387-0.72.hdf5
Epoch 388/400
200/200 [==============================] - 158s 789ms/step - loss: 0.6497 - acc: 0.8188 - val_loss: 0.9937 - val_acc: 0.7594

Epoch 00388: saving model to trial_2_output/weights-improvement-388-0.76.hdf5
Epoch 389/400
200/200 [==============================] - 152s 758ms/step - loss: 0.6761 - acc: 0.8143 - val_loss: 1.0932 - val_acc: 0.7375

Epoch 00389: saving model to trial_2_output/weights-improvement-389-0.74.hdf5
Epoch 390/400
200/200 [==============================] - 152s 760ms/step - loss: 0.6614 - acc: 0.8149 - val_loss: 1.0731 - val_acc: 0.7594

Epoch 00390: saving model to trial_2_output/weights-improvement-390-0.76.hdf5
Epoch 391/400
200/200 [==============================] - 151s 753ms/step - loss: 0.6783 - acc: 0.8125 - val_loss: 1.1193 - val_acc: 0.7438

Epoch 00391: saving model to trial_2_output/weights-improvement-391-0.74.hdf5
Epoch 392/400
200/200 [==============================] - 152s 761ms/step - loss: 0.6625 - acc: 0.8151 - val_loss: 1.2697 - val_acc: 0.7109

Epoch 00392: saving model to trial_2_output/weights-improvement-392-0.71.hdf5
Epoch 393/400
200/200 [==============================] - 158s 789ms/step - loss: 0.6954 - acc: 0.8063 - val_loss: 1.0468 - val_acc: 0.7672

Epoch 00393: saving model to trial_2_output/weights-improvement-393-0.77.hdf5
Epoch 394/400
200/200 [==============================] - 159s 793ms/step - loss: 0.6585 - acc: 0.8168 - val_loss: 1.0843 - val_acc: 0.7344

Epoch 00394: saving model to trial_2_output/weights-improvement-394-0.73.hdf5
Epoch 395/400
200/200 [==============================] - 160s 802ms/step - loss: 0.6671 - acc: 0.8155 - val_loss: 1.1247 - val_acc: 0.7250

Epoch 00395: saving model to trial_2_output/weights-improvement-395-0.72.hdf5
Epoch 396/400
200/200 [==============================] - 160s 798ms/step - loss: 0.6691 - acc: 0.8155 - val_loss: 1.1865 - val_acc: 0.7156

Epoch 00396: saving model to trial_2_output/weights-improvement-396-0.72.hdf5
Epoch 397/400
200/200 [==============================] - 158s 790ms/step - loss: 0.6670 - acc: 0.8146 - val_loss: 0.8790 - val_acc: 0.7953

Epoch 00397: saving model to trial_2_output/weights-improvement-397-0.80.hdf5
Epoch 398/400
200/200 [==============================] - 157s 784ms/step - loss: 0.6797 - acc: 0.8112 - val_loss: 0.9856 - val_acc: 0.7625

Epoch 00398: saving model to trial_2_output/weights-improvement-398-0.76.hdf5
Epoch 399/400
200/200 [==============================] - 157s 783ms/step - loss: 0.6453 - acc: 0.8198 - val_loss: 0.9011 - val_acc: 0.7891

Epoch 00399: saving model to trial_2_output/weights-improvement-399-0.79.hdf5
Epoch 400/400
200/200 [==============================] - 155s 777ms/step - loss: 0.6607 - acc: 0.8158 - val_loss: 1.1518 - val_acc: 0.7297

Epoch 00400: saving model to trial_2_output/weights-improvement-400-0.73.hdf5
Traceback (most recent call last):
  File "train_nikita2.py", line 122, in &lt;module&gt;
    a1.append(float(row[2]))#tacc
NameError: name 'a1' is not defined
</pre></div></div></div><span id="output-footer"></span></div></body><script>
  {
    const open = XMLHttpRequest.prototype.open;
    XMLHttpRequest.prototype.open = function (method, url) {
      open.apply(this, arguments);
      this.addEventListener('readystatechange', function _() {
        if(this.readyState == this.HEADERS_RECEIVED) {
          const contentType = this.getResponseHeader('Content-Type') || '';
          if (contentType.startsWith('video/') || contentType.startsWith('audio/')) {
            window.postMessage({
              source: 'xmlhttprequest-open',
              url,
              mime: contentType,
              method,
              contentType
            }, '*');
          }
          this.removeEventListener('readystatechange', _);
        }
      })
    }
  }
  </script></html>